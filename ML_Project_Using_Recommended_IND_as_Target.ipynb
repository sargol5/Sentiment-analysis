{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a68a2e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae504cfe",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Importing All Necessary Libraries</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61710f81",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6e030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21170383",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66ab7c",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Importing Dataset</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43587954",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fcfe2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'desktop/Womens Clothing E-Commerce Reviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qm/1kv48czd3n35vbttt232l4qm0000gn/T/ipykernel_56648/4250772315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"desktop/Womens Clothing E-Commerce Reviews.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'desktop/Womens Clothing E-Commerce Reviews.csv'"
     ]
    }
   ],
   "source": [
    "# Importing dataset\n",
    "review = pd.read_csv(\"desktop/Womens Clothing E-Commerce Reviews.csv\")\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab1732",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f623b61",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Data Cleaning</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41335053",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06815937",
   "metadata": {},
   "source": [
    "## Removing First Unnamed Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting first unnamed column\n",
    "review = review.loc[:, ~review.columns.str.contains('^Unnamed')]\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f78e571",
   "metadata": {},
   "source": [
    "## Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b28f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null value\n",
    "review.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4fabc",
   "metadata": {},
   "source": [
    "## Removing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting null values because it is less than 30% of whole data\n",
    "review = review.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b62ed",
   "metadata": {},
   "source": [
    "## Checking Null Values After Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null value after removing\n",
    "review.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225e02c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e113a92",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Data Exploration</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3afadc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4ebe0",
   "metadata": {},
   "source": [
    "## Number of Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows that there are 19662 rows and 10 columns\n",
    "review.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437152fe",
   "metadata": {},
   "source": [
    "## Datatype of Each Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258660e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows datatype of each column\n",
    "review.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51229fe6",
   "metadata": {},
   "source": [
    "## Describe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9162bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows count, mean, standard deviation, minimum, maximum, 25% 50% 75% percentiles\n",
    "review.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa2a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "review.describe(include=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c726b",
   "metadata": {},
   "source": [
    "## Count of Age of Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899b6b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(review.groupby('Age').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(review['Age'])\n",
    "plt.title('Count of Age of Reviewer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc909975",
   "metadata": {},
   "source": [
    "## Number of Customer's Positive and Negative Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri = review.groupby('Recommended IND').size()\n",
    "print(ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5287205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_labels = ['Not Recommended', 'Recommended']\n",
    "plt.pie(ri, labels=ri_labels, autopct='%.1f%%')\n",
    "plt.title('Number of Positive and Negative Reviews')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c77949",
   "metadata": {},
   "source": [
    "## Number of Different Divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404dc57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review.groupby('Division Name').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = review['Division Name'])\n",
    "plt.title('Number of Different Divisions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcacb414",
   "metadata": {},
   "source": [
    "## Number of Different Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdn = review.groupby('Department Name').size()\n",
    "print(rdn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdn_labels = review['Department Name'].unique()\n",
    "plt.pie(rdn, labels=rdn_labels, autopct='%.1f%%')\n",
    "plt.title('Number of Different Department')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b59385",
   "metadata": {},
   "source": [
    "## Number of Different Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review.groupby('Class Name').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = review['Class Name'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Number of Different Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423f54c",
   "metadata": {},
   "source": [
    "## Number of Customer's Rating from 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = review.groupby('Rating').size()\n",
    "print(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6024d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_labels = review['Rating'].unique()\n",
    "plt.pie(rr, labels=rr_labels, autopct='%.1f%%')\n",
    "plt.title('Number of Rating from 1 to 5')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3cd6a2",
   "metadata": {},
   "source": [
    "## Number of Positive Feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fda4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review.groupby('Positive Feedback Count').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a20b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(18,5)})\n",
    "sns.countplot(x = review['Positive Feedback Count'], label=\"Number of Visitors\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Number of Positive Feedbacks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832e962d",
   "metadata": {},
   "source": [
    "## Rating Compared to Recommended or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9babe3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data = review, x =\"Rating\", hue = \"Recommended IND\", kind='count', height=7, aspect=2.5, legend_out=False)\n",
    "\n",
    "plt.title('Rating Distribution By Recommendation', fontsize=26)\n",
    "plt.xlabel(\"Rating\", fontsize=20)\n",
    "plt.ylabel(\"Number of Recommendations\", fontsize=20)\n",
    "plt.legend(title='Recommendation Indicator', loc='upper left', labels=['Not Recomnended', 'Recomnended'], fontsize='x-large', title_fontsize='24')\n",
    "\n",
    "ax = g.facet_axis(0, 0)\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + 0.12, \n",
    "            p.get_height() * 1.025, \n",
    "            '{0:.0f}'.format(p.get_height()), \n",
    "            color='black', rotation='horizontal', size='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e87fca",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f067ff8",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Data Preprocessing</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a3644",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d192ff7",
   "metadata": {},
   "source": [
    "## Before Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Title'].loc[510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Review Text'].loc[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97febf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = review['Review Text'].str.split(expand=True).stack().value_counts()\n",
    "words200 = words[:200]\n",
    "fig = px.treemap(words200, path=[words200.index], values=0, width=900, height=900)\n",
    "fig.update_layout(title_text='Top Frequent 200 Words in Review Text (Before Processing)')\n",
    "fig.update_traces(textinfo=\"label+value\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb3a0e",
   "metadata": {},
   "source": [
    "## Initializing Classes for Text Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25033518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Special Characters in Sentence\n",
    "# ^ (Do Not  match) \\w (alphanumeric characters) and \\s (white space and tab)\n",
    "def removing_special_character(text):\n",
    "    new_text = re.sub('[^\\w\\s]','', text)\n",
    "    return new_text\n",
    "\n",
    "# Tokenizing Sentence with all lower case\n",
    "def tokenize_sentence(text):\n",
    "    text_tokens = nltk.word_tokenize(text.lower())\n",
    "    return text_tokens\n",
    "\n",
    "# Removing Numbers from text sentence\n",
    "def removing_numbers(text):\n",
    "    new_text = [x for x in text if x.isalpha()]\n",
    "    return new_text\n",
    "\n",
    "# Removing Stopwords from text sentence\n",
    "def removing_stopwords(text):\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    new_text = [x for x in text if x not in stopwords]\n",
    "    return new_text\n",
    "\n",
    "# Lemmatizing Sentence\n",
    "def lemmatizer(text):\n",
    "    new_text = [WordNetLemmatizer().lemmatize(x) for x in text]\n",
    "    return new_text\n",
    "\n",
    "# Joining the Tokenized Sentences\n",
    "def join_token(text):\n",
    "     return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c09fe3",
   "metadata": {},
   "source": [
    "## Processing Title Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ebfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Title'] = review['Title'].apply(removing_special_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831acae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Title'] = review['Title'].apply(tokenize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ab37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Title'] = review['Title'].apply(removing_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Title'] = review['Title'].apply(removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce718a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Title'] = review['Title'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Title'] = review['Title'].apply(join_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096736f",
   "metadata": {},
   "source": [
    "## Processing Review Text Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21976b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Review Text'] = review['Review Text'].apply(removing_special_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6404312",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Review Text'] = review['Review Text'].apply(tokenize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Review Text'] = review['Review Text'].apply(removing_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Review Text'] = review['Review Text'].apply(removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca728ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Review Text'] = review['Review Text'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Review Text'] = review['Review Text'].apply(join_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7edf757",
   "metadata": {},
   "source": [
    "## After Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Title'].loc[510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1605031",
   "metadata": {},
   "outputs": [],
   "source": [
    "review['Review Text'].loc[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = review['Review Text'].str.split(expand=True).stack().value_counts()\n",
    "words200 = words[:200]\n",
    "fig = px.treemap(words200, path=[words200.index], values=0, width=900, height=900)\n",
    "fig.update_layout(title_text='Top Frequent 200 Words in Review Text (After Processing)')\n",
    "fig.update_traces(textinfo=\"label+value\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a275f",
   "metadata": {},
   "source": [
    "## Frequent Words in Positive Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ac87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = review[review['Recommended IND']==1].copy()\n",
    "\n",
    "positive_words = positive['Review Text'].str.split(expand=True).stack().value_counts()\n",
    "words200 = positive_words[:200]\n",
    "fig = px.treemap(words200, path=[words200.index], values=0, width=900, height=900)\n",
    "fig.update_layout(title_text='Top Frequent 200 Positive Words in Review Text (After Processing)')\n",
    "fig.update_traces(textinfo=\"label+value\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24663861",
   "metadata": {},
   "source": [
    "## Frequent Words in Negative Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d42b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = review[review['Recommended IND']==0].copy()\n",
    "\n",
    "negative_words = negative['Review Text'].str.split(expand=True).stack().value_counts()\n",
    "words200 = negative_words[:200]\n",
    "fig = px.treemap(words200, path=[words200.index], values=0, width=900, height=900)\n",
    "fig.update_layout(title_text='Top Frequent 200 Negative Words in Review Text (After Processing)')\n",
    "fig.update_traces(textinfo=\"label+value\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f19ada",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37147fc3",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>1. Predicting using only Review Text</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea48ce",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495870b",
   "metadata": {},
   "source": [
    "## Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286cfd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = review[\"Review Text\"]\n",
    "Y1 = review[\"Recommended IND\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c337989",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 80% Training Set and 20% Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting test train data\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y1, test_size=0.2)\n",
    "\n",
    "print('Training Set:\\tX1_train: ', X1_train.shape, ', Y1_train: ', Y1_train.shape, \n",
    "      '\\nTesting Set:\\tX1_test: ', X1_test.shape, ', Y1_test: ', Y1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb36008",
   "metadata": {},
   "source": [
    "## Converting into Vectorize Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c787d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X1_train = vectorizer.fit_transform(X1_train)\n",
    "X1_test = vectorizer.transform(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6057b5f",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X1_train, Y1_train)\n",
    "\n",
    "nb_predict1 = nb.predict(X1_test)\n",
    "\n",
    "print('Accuracy of Naive Bayes: {:.2f}'.format(nb.score(X1_test, Y1_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7c3f7",
   "metadata": {},
   "source": [
    "## Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix of Naive Bayes using testset output and predicted output\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(Y1_test, nb_predict1))\n",
    "\n",
    "# Classification Report of Naive Bayes using testset output and predicted output\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(Y1_test, nb_predict1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6336e5f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79146c9b",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>2. Predicting using only Review Text where Positive Feedback Count is greater than 1</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28451302",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd5e0b",
   "metadata": {},
   "source": [
    "## Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = review.loc[review['Positive Feedback Count'] > 1]\n",
    "X2 = r2['Review Text']\n",
    "Y2 = r2['Recommended IND']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692cb466",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 80% Training Set and 20% Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0dbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting test train data\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2, Y2, test_size=0.2)\n",
    "\n",
    "print('Training Set:\\tX2_train: ', X2_train.shape, ', Y2_train: ', Y2_train.shape, \n",
    "      '\\nTesting Set:\\tX2_test: ', X2_test.shape, ', Y2_test: ', Y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d112a",
   "metadata": {},
   "source": [
    "## Converting into Vectorize Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340262f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X2_train = vectorizer.fit_transform(X2_train)\n",
    "X2_test = vectorizer.transform(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe3885d",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X2_train, Y2_train)\n",
    "\n",
    "nb_predict2 = nb.predict(X2_test)\n",
    "\n",
    "print('Accuracy of Naive Bayes: {:.2f}'.format(nb.score(X2_test, Y2_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba637a6f",
   "metadata": {},
   "source": [
    "## Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix of Naive Bayes using testset output and predicted output\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(Y2_test, nb_predict2))\n",
    "\n",
    "# Classification Report of Naive Bayes using testset output and predicted output\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(Y2_test, nb_predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fee28",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bcc5f",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>3. Predicting using only Title</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdb762",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077817a",
   "metadata": {},
   "source": [
    "## Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = review['Title']\n",
    "Y3 = review['Recommended IND']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0f89f",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 80% Training Set and 20% Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ae4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting test train data\n",
    "X3_train, X3_test, Y3_train, Y3_test = train_test_split(X3, Y3, test_size=0.2)\n",
    "\n",
    "print('Training Set:\\tX3_train: ', X3_train.shape, ', Y3_train: ', Y3_train.shape, \n",
    "      '\\nTesting Set:\\tX3_test: ', X3_test.shape, ', Y3_test: ', Y3_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd66a6b",
   "metadata": {},
   "source": [
    "## Converting into Vectorize Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36813d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X3_train = vectorizer.fit_transform(X3_train)\n",
    "X3_test = vectorizer.transform(X3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e6691",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X3_train, Y3_train)\n",
    "\n",
    "nb_predict3 = nb.predict(X3_test)\n",
    "\n",
    "print('Accuracy of Naive Bayes: {:.2f}'.format(nb.score(X3_test, Y3_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023fd5c",
   "metadata": {},
   "source": [
    "## Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b30c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix of Naive Bayes using testset output and predicted output\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(Y3_test, nb_predict3))\n",
    "\n",
    "# Classification Report of Naive Bayes using testset output and predicted output\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(Y3_test, nb_predict3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e58ebe",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914251c3",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>4. Predicting using only Title where Positive Feedback Count is greater than 1</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5684b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed145dc",
   "metadata": {},
   "source": [
    "## Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fadddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 = review.loc[review['Positive Feedback Count'] > 1]\n",
    "X4 = r4['Title']\n",
    "Y4 = r4['Recommended IND']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b9d07",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 80% Training Set and 20% Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5cad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting test train data\n",
    "X4_train, X4_test, Y4_train, Y4_test = train_test_split(X4, Y4, test_size=0.2)\n",
    "\n",
    "print('Training Set:\\tX4_train: ', X4_train.shape, ', Y4_train: ', Y4_train.shape, \n",
    "      '\\nTesting Set:\\tX4_test: ', X4_test.shape, ', Y4_test: ', Y4_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ab02b",
   "metadata": {},
   "source": [
    "## Converting into Vectorize Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c18227",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X4_train = vectorizer.fit_transform(X4_train)\n",
    "X4_test = vectorizer.transform(X4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d54211",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X4_train, Y4_train)\n",
    "\n",
    "nb_predict4 = nb.predict(X4_test)\n",
    "\n",
    "print('Accuracy of Naive Bayes: {:.2f}'.format(nb.score(X4_test, Y4_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90672d31",
   "metadata": {},
   "source": [
    "## Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix of Naive Bayes using testset output and predicted output\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(Y4_test, nb_predict4))\n",
    "\n",
    "# Classification Report of Naive Bayes using testset output and predicted output\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(Y4_test, nb_predict4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed7aee",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258f5a6",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>5. Predicting using Recommended IND and Positive Feedback Count</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2c1d2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc85d3",
   "metadata": {},
   "source": [
    "## Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = review[['Rating', 'Positive Feedback Count']]\n",
    "Y5 = review['Recommended IND']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd582c93",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 80% Training Set and 20% Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting test train data\n",
    "X5_train, X5_test, Y5_train, Y5_test = train_test_split(X5, Y5, test_size=0.2)\n",
    "\n",
    "print('Training Set:\\tX5_train: ', X5_train.shape, ', Y5_train: ', Y5_train.shape, \n",
    "      '\\nTesting Set:\\tX5_test: ', X5_test.shape, ', Y5_test: ', Y5_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae4580",
   "metadata": {},
   "source": [
    "## Converting into Vectorize Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "# X5_train = vectorizer.fit_transform(X5_train)\n",
    "# X5_test = vectorizer.transform(X5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6194f",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0cd300",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X5_train, Y5_train)\n",
    "\n",
    "nb_predict5 = nb.predict(X5_test)\n",
    "\n",
    "print('Accuracy of Naive Bayes: {:.2f}'.format(nb.score(X5_test, Y5_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93274d96",
   "metadata": {},
   "source": [
    "## Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix of Naive Bayes using testset output and predicted output\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(Y4_test, nb_predict4))\n",
    "\n",
    "# Classification Report of Naive Bayes using testset output and predicted output\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(Y4_test, nb_predict4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2291956",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42d4e5",
   "metadata": {},
   "source": [
    "1. Predicting using only Review Text\n",
    "\n",
    "2. Predicting using only Review Text where Positive Feedback Count is greater than 1\n",
    "\n",
    "3. Predicting using only Title\n",
    "\n",
    "4. Predicting using only Title where Positive Feedback Count is greater than 1\n",
    "\n",
    "5. Predicting using Rating and Positive Feedback Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a6ec3",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
